{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src import run_experiments as re\n",
    "from motif.contour_extractors.salamon import Salamon\n",
    "from motif.run import process\n",
    "import properties as prop\n",
    "import motif.core as core\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "\n",
    "outdir = os.getcwd() + prop.relOutputDir\n",
    "MEL_TYPE = 1\n",
    "NO_EXPERIMENTO = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Todos os pares (arquivo_de_notacao nome_arquivo_audio_MELODY{1,2,3}.csv, nome_arquivo_audio.WAV) são \n",
    "selecionados de experiment_splits.json, da chave NO_EXPERIMENTO (1 a 5) e da subchave 'train', guardados\n",
    "na variável pares\n",
    "e os arquivos de teste provenientes da subchave 'test' são guardados em audios_file\n",
    "e todos as musicas utilizadas nos testes e treino sao gravadas em track_list\n",
    "\"\"\"\n",
    "def get_audio_files_training_pairs_track_list(experiment_number = 1, mel_type = 1):\n",
    "    #pares de treinamento vindos do MEDLEY\n",
    "    annotationDir = prop.melodyRoot + str(mel_type) + \"/\"\n",
    "    audio_root = prop.audioRoot\n",
    "    SUFIX = \"_MELODY\" + str(mel_type) + \".csv\"\n",
    "    EXPERIMENT_NUMBER_STR = str(experiment_number)\n",
    "    track_list = []\n",
    "    training_pairs = []\n",
    "    audio_files = [] \n",
    "    jsonDir = os.getcwd().split(prop.projectDirName)[0] + prop.projectDirName + \"/\" + prop.testDataName + \"/\"\n",
    "    jsonFile = jsonDir + prop.experimentSplits\n",
    "    with open(jsonFile, 'r') as fhandle:\n",
    "        all_track_list = json.load(fhandle)\n",
    "        for track in all_track_list[EXPERIMENT_NUMBER_STR]['train']:\n",
    "            annotation = annotationDir + track + SUFIX\n",
    "            audio_file = audio_root + track + \"/\" + track + \"_MIX.wav\"\n",
    "            training_pairs.append((audio_file, annotation))\n",
    "            track_list.append(track)\n",
    "        for track in all_track_list[EXPERIMENT_NUMBER_STR]['test']:\n",
    "            audio_files.append(audio_root + track + \"/\" + track + \"_MIX.wav\")\n",
    "            track_list.append(track)\n",
    "    #todos os caminhos de experiment_splits.json\n",
    "#     with open(jsonFile, 'r') as fhandle:\n",
    "#         all_track_list = json.load(fhandle)\n",
    "#         for track in all_track_list[EXPERIMENT_NUMBER_STR]['test']:\n",
    "#             audio_files.append(audio_root + track + \"/\" + track + \"_MIX.wav\")\n",
    "            \n",
    "    return audio_files, training_pairs, track_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_contours(audio_files, training_pairs, track_list):\n",
    "    #extrai os contornos dos arquivos \n",
    "    contours_root = prop.contoursRoot\n",
    "    \n",
    "    for nome in(track_list):\n",
    "        # cria o diretorio\n",
    "        contour_dir = contours_root + nome\n",
    "        try:\n",
    "            os.stat(contour_dir)\n",
    "        except:\n",
    "            os.mkdir(contour_dir)\n",
    "\n",
    "    results = process(\n",
    "            audio_files=audio_files, training_pairs=training_pairs,\n",
    "            testing_pairs=None, extract_id='salamon',\n",
    "            feature_id='melodia', classifier_id='random_forest')\n",
    "    \n",
    "    #results = {training contours, test contours + test features extracted}\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def salva(array, output_fpath):\n",
    "    with open(output_fpath, 'w') as fhandle:\n",
    "        writer = csv.writer(fhandle, delimiter=',')\n",
    "        writer.writerows(item for item in array)\n",
    "        \n",
    "def save_contours_and_features(results):\n",
    "    contours_root = prop.contoursRoot\n",
    "    for treinada in results[0]:\n",
    "        caminho = contours_root + treinada.audio_filepath.split('Audio')[1][0:-4] + \"_TREINO.csv\"\n",
    "        treinada.save(caminho)\n",
    "    \"\"\"\n",
    "     salvando os contornos obtidos e as features \n",
    "     (onset', 'offset', 'duration', 'pitch mean', 'pitch std',\n",
    "     'salience mean', 'salience std', 'salience tot',\n",
    "     'vibrato', 'vib rate', 'vib extent', 'vib coverage')\n",
    "     e fazendo uma matrix que em cada linha coloca todas os tempo, freqs, saliencias\n",
    "     dentro do intervalo de onset e offset\n",
    "    \"\"\"\n",
    "    novaMatriz = []\n",
    "    dimMax = 0\n",
    "    for resultado in results[1]:\n",
    "        caminho = contours_root + resultado[0].audio_filepath.split('Audio')[1][0:-4] + \".csv\"\n",
    "        #objeto contorno\n",
    "        contorno = resultado[0]\n",
    "        contorno.save(caminho)\n",
    "        #features\n",
    "        features = resultado[1]\n",
    "        probs = np.asarray(resultado[2])\n",
    "        probsT = np.resize(probs, (probs.shape[0],1))\n",
    "        featuresProbs = np.concatenate((features, probsT), axis=1)\n",
    "        caminho_csv = caminho[0:-4] + \"_RESULT.csv\"\n",
    "        #fazendo o mix\n",
    "        #cria uma lista de copia\n",
    "        novaMatriz = featuresProbs.tolist()\n",
    "        dimMax = 0\n",
    "        for featureIndex in range(featuresProbs.shape[0]):\n",
    "            linha = novaMatriz[featureIndex]\n",
    "            onset = linha[0]\n",
    "            offset = linha[1]\n",
    "            for timeIndex in range(len(contorno.times)):\n",
    "                time = contorno.times[timeIndex]\n",
    "                if(onset <= time and time <= offset):\n",
    "                    freq = contorno.freqs[timeIndex]\n",
    "                    sals = contorno.salience[timeIndex]\n",
    "                    linha.append(time)\n",
    "                    linha.append(freq)\n",
    "                    linha.append(sals)\n",
    "                    del novaMatriz[featureIndex]\n",
    "                    novaMatriz.insert(featureIndex, linha)\n",
    "                    dimMax = len(linha) if len(linha) > dimMax else dimMax\n",
    "#                 elif(time > offset):\n",
    "#                     break\n",
    "        #preenchendo as linhas com NaN para a matriz ficar completa \n",
    "        nan = float('nan')\n",
    "        for linha in novaMatriz:\n",
    "            tamanho = len(linha)\n",
    "            while(tamanho < dimMax):\n",
    "                linha.append(nan)\n",
    "                tamanho += 1\n",
    "        novaMatriz = np.asarray(novaMatriz)\n",
    "        salva(novaMatriz, caminho_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento  1\n",
      "Extraindo contornos...\n",
      "Salvando...\n",
      "Experimento  2\n",
      "Extraindo contornos..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Dados/Google Drive/Estudos/Mestrado/workspace/python/contour_classification/mir_eval/melody.py:231: UserWarning: Non-uniform timescale passed to resample_melody_series.  Pitch will be linearly interpolated, which will result in undesirable behavior if silences are indicated by missing values.  Silences should be indicated by nonpositive frequency values.\n",
      "  \"Non-uniform timescale passed to resample_melody_series.  Pitch \"\n",
      "/Volumes/Dados/Google Drive/Estudos/Mestrado/workspace/python/contour_classification/mir_eval/melody.py:77: UserWarning: Reference melody has no voiced frames.\n",
      "  warnings.warn(\"Reference melody has no voiced frames.\")\n",
      "/Volumes/Dados/Google Drive/Estudos/Mestrado/workspace/python/contour_classification/mir_eval/melody.py:231: UserWarning: Non-uniform timescale passed to resample_melody_series.  Pitch will be linearly interpolated, which will result in undesirable behavior if silences are indicated by missing values.  Silences should be indicated by nonpositive frequency values.\n",
      "  \"Non-uniform timescale passed to resample_melody_series.  Pitch \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salvando...\n",
      "Experimento "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Dados/Google Drive/Estudos/Mestrado/workspace/python/contour_classification/mir_eval/melody.py:77: UserWarning: Reference melody has no voiced frames.\n",
      "  warnings.warn(\"Reference melody has no voiced frames.\")\n",
      "/Volumes/Dados/Google Drive/Estudos/Mestrado/workspace/python/contour_classification/mir_eval/melody.py:231: UserWarning: Non-uniform timescale passed to resample_melody_series.  Pitch will be linearly interpolated, which will result in undesirable behavior if silences are indicated by missing values.  Silences should be indicated by nonpositive frequency values.\n",
      "  \"Non-uniform timescale passed to resample_melody_series.  Pitch \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3\n",
      "Extraindo contornos...\n",
      "Salvando...\n",
      "Experimento "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Dados/Google Drive/Estudos/Mestrado/workspace/python/contour_classification/mir_eval/melody.py:77: UserWarning: Reference melody has no voiced frames.\n",
      "  warnings.warn(\"Reference melody has no voiced frames.\")\n",
      "/Volumes/Dados/Google Drive/Estudos/Mestrado/workspace/python/contour_classification/mir_eval/melody.py:231: UserWarning: Non-uniform timescale passed to resample_melody_series.  Pitch will be linearly interpolated, which will result in undesirable behavior if silences are indicated by missing values.  Silences should be indicated by nonpositive frequency values.\n",
      "  \"Non-uniform timescale passed to resample_melody_series.  Pitch \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4\n",
      "Extraindo contornos...\n",
      "Salvando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Dados/Google Drive/Estudos/Mestrado/workspace/python/contour_classification/mir_eval/melody.py:77: UserWarning: Reference melody has no voiced frames.\n",
      "  warnings.warn(\"Reference melody has no voiced frames.\")\n"
     ]
    }
   ],
   "source": [
    "for no_exper in range(1,5):\n",
    "    print(\"Experimento \", no_exper)\n",
    "    audios, trainings, tracks = get_audio_files_training_pairs_track_list(no_exper, MEL_TYPE)\n",
    "    print(\"Extraindo contornos...\")\n",
    "    results = extract_contours(audios, trainings, tracks)\n",
    "    print(\"Salvando...\")\n",
    "    save_contours_and_features(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
